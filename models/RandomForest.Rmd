---
title: "Random Forest"
author: "Charlotte Uden"
date: "2025-08-29"
output: html_document
---

```{r}
library(randomForest)
library(dplyr)
```

Load configuration files
- location of climate and lighting drivers
- location to store rds files - these files are generated by rstan and contain the saved models
- location to store tables containing parameter estimates, model predictions, and performance metrics
```{r}
read_properties <- function(file_path) {
  lines <- readLines(file_path)
  lines <- lines[grepl("=", lines)]  # only keep lines with key-value pairs
  key_vals <- strsplit(lines, "=")
  props <- setNames(
    trimws(sapply(key_vals, `[`, 2)),
    trimws(sapply(key_vals, `[`, 1))
  )
  return(props)
}

config <- read_properties("/path/to/config/file/my_config.properties")  # path to your config file

# Extract values from config
data_root <- config[["data_root"]]
rds_file_path <- config[["rds_root"]]
table_file_path <- config[["table_root"]]

# Use the values to build full paths
drivers_file_path <- file.path(data_root, "monthly_drivers.csv")
```


```{r}
df <- read.csv(drivers_file_path)
head(df)
#rename columns if necessary
#colnames(df) <- c("lon", "lat", "year", "strikes", "cape", "precip", "cxp", "tair", "wind", "swr", "sp", "rh")

```

```{r}
df <- df[c("strikes", "cxp", "precip", "tair", "wind", "swr", "sp", "rh")]

#check for correlation between variables
#draw random sample of rows to plot 
df_sample <- df %>% sample_frac(0.1)
plot(df_sample)

#apply random forest:
rf <-randomForest(strikes~.,data=df, ntree=500) 
print(rf)

#mtry: Number of random variables used in each tree
# - reducing mtry reduces correlation and strength. 
# - the oob error rate tells you what value of mtry is optimal

mtry <- tuneRF(df[-1],df$strikes, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
#looking for mtry for the lowest oob error rate 
print(mtry)
print(best.m) 

#apply best mtry to model
rf <-randomForest(strikes~.,data=df, mtry=best.m, importance=TRUE,ntree=500)
print(rf)

#Evaluate variable importance
importance(rf)
varImpPlot(rf)


```
# Mean Decrease Accuracy (%IncMSE):
- remove variables from the model and asses which have the greatest impact on model accuracy.
- Higher the value of mean decrease accuracy or mean decrease gini score ,
       higher the importance of the variable in the model.
- tells you effect of randomly shuffling values of a variable on increasing mse of model predictions
- a higher number indicates that the variable is more important

# Mean Decrease Gini or Increase in Node Purity (IncNodePurity):
- expresses the change in the homogeneity of the of the groups created by the trees
     (using the Gini coefficient as a measure).
- What is expressed is the decrease in said purity if a particular variable
      has no information. If a variable has no information to begin with,
      the decrase would be zero. (from: https://www.reagro.org/methods/statistical/randomforest.html)














